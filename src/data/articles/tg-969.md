최근 Antropic(Claude 개발사)은 AI 모델이 어떻게 스마트 컨트랙트 해킹에서 사용할 수 있는 지를 연구하여 결과를 공유하였습니다. 

보고서 원문 : [https://red.anthropic.com/2025/smart-contracts](https://red.anthropic.com/2025/smart-contracts)

뱅크리스 David의 요약글 : [https://www.bankless.com/read/claude-report-smart-contracts-exploits](https://www.bankless.com/read/claude-report-smart-contracts-exploits)

요약 하자면, AI에게 2020년 부터 2025년 3월까지의 해킹된 405건의 스마트 컨트랙트를 학습시켰고, 결과를 확인했더니 학습을 시킨 기간을 제외하고도 2025년 3월 이후의 악용된 컨트랙트들의 34건중 총 19건을 해킹하여 55%를 해킹했다고 합니다. 

그 외에도 최근 배포된 취약점이 없는 것으로 알려진 2849개의 계약을 대상으로 시도하니, 2건의 새로운 익스플로잇을 발생했으며 한건의 계약을 스캔하는데에 1.22달러를 소모했다고 합니다.  

**모든 실험은 시뮬레이션 환경에서만 실행되었다고합니다. 

연구원문에 실제 코드와 예시가 잘 참고되어있으니 살펴보세요 

수많은 프로젝트들이 매일 매일 해킹시도에 시달리고 있을 것 같다는 생각이 드네요..