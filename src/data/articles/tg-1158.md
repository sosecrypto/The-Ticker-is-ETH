비탈릭: 내가 생각하는 "보안"이란

목표는 사용자의 의도와 시스템의 실제 동작 사이의 괴리를 최소화하는 것입니다.

"사용자 경험(UX)" 또한 이런 방식으로 정의될 수 있습니다. 따라서 "사용자 경험"과 "보안"은 서로 분리된 분야가 아닙니다. 다만, "보안"은 꼬리 위험(tail risk) 상황(괴리로 인한 부정적 영향이 큰 경우), 특히 적대적 행위의 결과로 발생하는 꼬리 위험 상황에 집중합니다.

위의 정의에서 즉각적으로 명확해지는 한 가지는 "완벽한 보안"이란 불가능하다는 점입니다. 이는 기계가 "결함이 있어서" 혹은 기계를 설계하는 인간이 "결함이 있어서"가 아니라, "사용자의 의도"라는 것 자체가 근본적으로 사용자 자신조차 쉽게 파악하기 어려운 매우 복잡한 대상이기 때문입니다.

사용자의 의도가 "밥(Bob)에게 1 ETH를 보내고 싶다"라고 가정해 봅시다. 하지만 "밥"이라는 존재 자체가 수학적으로 쉽게 정의될 수 없는 복잡한 현실 세계의 실체입니다. 밥을 특정 공개 키나 해시로 "표현"할 수는 있겠지만, 그렇게 되면 해당 공개 키나 해시가 실제로는 밥이 아닐 가능성이 위협 모델의 일부가 됩니다. 또한 논쟁적인 하드 포크가 발생할 가능성도 있으며, 이 경우 어떤 체인이 "ETH"를 나타내는지에 대한 문제는 주관적이 됩니다. 실제로 사용자는 이러한 주제들에 대해 "상식"이라는 포괄적인 용어로 요약되는 잘 형성된 관념을 가지고 있지만, 이러한 것들은 수학적으로 쉽게 정의되지 않습니다.

사용자의 목표가 더 복잡해지면(예를 들어 "사용자의 프라이버시 보호"라는 목표를 예로 들면) 문제는 훨씬 더 까다로워집니다. 많은 사람이 직관적으로 메시지를 암호화하는 것만으로 충분하다고 생각하지만, 실제로는 누가 누구와 대화하는지에 대한 메타데이터 패턴이나 메시지 사이의 시간 간격 패턴 등이 엄청난 양의 정보를 유출할 수 있습니다. 무엇이 "사소한" 프라이버시 손실이고, 무엇이 "치명적인" 손실일까요?

만약 당신이 AI 안전에 관한 초기 유드코프스키적 사고방식에 익숙하고, 목표를 견고하게 규정하는 것 자체가 문제의 가장 어려운 부분 중 하나라는 점을 알고 있다면, 이것이 동일한 문제라는 것을 깨닫게 될 것입니다.

"좋은 보안 솔루션"이란 어떤 모습일까요?

이는 다음에 적용됩니다: 이더리움 지갑, 운영 체제, 스마트 컨트랙트/클라이언트/기타 컴퓨터 프로그램의 형식 검증(Formal verification), 하드웨어 등.

근본적인 제약은 다음과 같습니다. 사용자가 시스템에 입력할 수 있는 모든 것은 본질적으로 그들의 의도를 온전히 담아내기에는 복잡도가 너무 낮다는 점입니다. 저는 좋은 해결책의 공통된 특징이 다음과 같다고 주장합니다. 즉, 사용자가 자신의 의도를 중첩되는 여러 방식으로 명시하고, 시스템은 이러한 명시된 내용들이 서로 일치할 때만 작동하는 것입니다.

예시:

1. 프로그래밍의 타입 시스템: 프로그래머는 먼저 '프로그램이 무엇을 하는지'(코드 자체)를 명시한 다음, '계산의 각 단계에서 각 데이터 구조가 어떤 형태를 갖는지'도 명시합니다. 만약 이 두 가지가 어긋나면 프로그램은 컴파일에 실패합니다.

2. 형식 검증(Formal verification): 프로그래머가 프로그램이 수행하는 작업(코드 자체)을 명시한 다음, 해당 프로그램이 충족하는 수학적 속성 또한 명시합니다.

3. 트랜잭션 시뮬레이션: 사용자가 먼저 취하고자 하는 작업을 지정한 후, 해당 작업이 온체인에 미칠 영향에 대한 시뮬레이션을 확인하고 "확인" 또는 "취소"를 클릭합니다.

4. 트랜잭션 내 사후 확언(Post-assertions): 트랜잭션에 작업 내용과 예상되는 결과가 모두 명시되며, 트랜잭션이 실행되려면 두 가지가 모두 일치해야 합니다.

5. 멀티시그 / 소셜 복구: 사용자가 자신의 권한을 나타내는 여러 개의 키를 지정합니다.

6. 지출 한도, 새 주소 확인 등: 사용자가 먼저 수행하려는 작업을 지정한 다음, 해당 작업이 어떤 의미에서 "비정상적"이거나 "고위험"인 경우, 사용자는 "네, 제가 비정상적/고위험 작업을 수행하고 있음을 알고 있습니다"라고 다시 지정해야 합니다.

모든 경우에 패턴은 동일합니다. 완벽함이란 없으며, 중복성을 통한 위험 감소만이 존재할 뿐입니다. 그리고 서로 다른 중복된 지정 방식들이 다양한 "각도"에서 "사용자의 의도에 접근"하기를 원할 것입니다. 예를 들어 작업 내용, 예상되는 결과, 예상되는 중요도 수준, 손실에 대한 경제적 한도 등이 그 예입니다.

LLM의 역할

이러한 사고방식은 LLMs를 사용하는 올바른 방법에 대한 힌트도 제공합니다. 제대로 활용된 LLMs는 그 자체로 의도의 시뮬레이션입니다. 일반적인 LLM은 (다른 여러 기능 중에서도) 인간의 상식이라는 개념의 "그림자"와 같습니다. 사용자에게 맞춤형으로 미세 조정된 LLM은 사용자 자신의 "그림자"와 같아서, 무엇이 정상이고 무엇이 비정상인지를 더 세밀하게 식별할 수 있습니다.

LLMs는 어떠한 경우에도 의도를 결정하는 유일한 요소로 신뢰되어서는 안 됩니다. 하지만 LLMs는 사용자의 의도를 근사화할 수 있는 하나의 "각도"입니다. 이는 의도를 인코딩하는 전통적이고 명시적인 방식과는 매우 다른 각도이며, 그 차이 자체가 중복성이 유용하다는 것을 증명할 가능성을 극대화합니다.

마지막 결론

또 다른 당연한 결과는 "보안"이 "사용자가 모든 작업에 대해 더 많은 클릭을 하게 만드는 것"을 의미하지 않는다는 점입니다. 오히려 보안이란, 위험도가 낮은 일은 (자동화되지는 않더라도) 수행하기 쉬워야 하고, 위험한 일은 수행하기 어려워야 함을 의미해야 합니다. 이 균형을 올바르게 맞추는 것이 과제입니다.

출처